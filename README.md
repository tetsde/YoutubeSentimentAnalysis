# üéØ Social Media Listen Tool - YouTube Sentiment Analysis

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Production-success.svg)

**Automated YouTube Comment Sentiment Analysis with Modern Visualization**

[Features](#-features) ‚Ä¢ [Installation](#-installation) ‚Ä¢ [Usage](#-usage) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Configuration](#%EF%B8%8F-configuration)

</div>

---

## üìã Overview

Social Media Listen Tool is an **end-to-end automated pipeline** for analyzing YouTube comment sentiment in Vietnamese. Built with **sklearn MultinomialNB** and **modern data visualization**, it provides actionable insights into audience opinions.

### üéØ What it does:

```
YouTube Video ‚Üí Scrape Comments ‚Üí Clean Data ‚Üí AI Analysis ‚Üí Beautiful Visualizations
```

---

## ‚ú® Features

### ü§ñ **Fully Automated Pipeline**
- ‚úÖ **Selenium-based scraper** with auto-scroll for lazy-loaded comments
- ‚úÖ **Smart data cleaning** with Vietnamese text processing
- ‚úÖ **Machine Learning** sentiment classification (85%+ accuracy)
- ‚úÖ **Modern dark-theme visualizations** with word clouds & charts

### üöÄ **Production-Ready**
- ‚úÖ **Centralized configuration** (`config.py`)
- ‚úÖ **Utility functions** to eliminate code duplication
- ‚úÖ **Proper logging** with INFO/ERROR/DEBUG levels
- ‚úÖ **Error handling** at every pipeline stage
- ‚úÖ **Auto file management** with timestamps

### üìä **Professional Visualizations**
- ‚úÖ **Gradient Word Cloud** - Top 150 Vietnamese keywords
- ‚úÖ **Donut Chart** - Sentiment distribution (Positive/Neutral/Negative)
- ‚úÖ **Statistics Panel** - Sample counts, vocabulary size

---

## üõ† Technologies

| Component | Technology |
|-----------|-----------|
| **Web Scraping** | Selenium + WebDriver Manager |
| **Data Processing** | Pandas + NumPy |
| **NLP** | pyvi (Vietnamese tokenization) |
| **Machine Learning** | scikit-learn (MultinomialNB + CountVectorizer) |
| **Visualization** | Matplotlib + WordCloud |

---

## üì¶ Installation

### Prerequisites
- **Python 3.9+**
- **Google Chrome** browser

### Steps

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/SocialMediaListenTool.git
cd SocialMediaListenTool
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Verify installation**
```bash
python -c "from modules.AIModel import SentimentClassifier; print('‚úÖ Installation successful!')"
```

---

## üöÄ Usage

### Quick Start

```python
from main import SocialMediaListenTool

# Set YouTube URL
url = "https://www.youtube.com/watch?v=VIDEO_ID"

# Run complete pipeline
tool = SocialMediaListenTool(url)
tool.run()
```

### Command Line

```bash
# Edit URL in main.py, then run:
python main.py
```

### Output

```
üìÅ Project Structure After Run:
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw_comments_2026-01-14_17-08-48.csv      # Scraped data
‚îÇ   ‚îî‚îÄ‚îÄ clean_comments_2026-01-14_17-08-48.csv    # Cleaned data
‚îú‚îÄ‚îÄ result/
‚îÇ   ‚îî‚îÄ‚îÄ test_results_2026-01-14_17-08-48.csv      # Predictions
‚îî‚îÄ‚îÄ modules/
    ‚îî‚îÄ‚îÄ model.pkl                                  # Trained model
```

---

## üèó Architecture

### Project Structure

```
SocialMediaListenTool/
‚îú‚îÄ‚îÄ main.py                       # Pipeline orchestrator
‚îú‚îÄ‚îÄ config.py                     # Centralized configuration
‚îú‚îÄ‚îÄ utils.py                      # Common utility functions
‚îú‚îÄ‚îÄ requirements.txt              # Dependencies
‚îÇ
‚îú‚îÄ‚îÄ modules/                      # Core components
‚îÇ   ‚îú‚îÄ‚îÄ YoutubeCommentScraper.py # Comment scraping
‚îÇ   ‚îú‚îÄ‚îÄ Cleaner.py               # Data cleaning
‚îÇ   ‚îú‚îÄ‚îÄ AIModel.py               # Sentiment classifier
‚îÇ   ‚îî‚îÄ‚îÄ model.pkl                # Trained ML model
‚îÇ
‚îú‚îÄ‚îÄ reports/                      # Visualization
‚îÇ   ‚îî‚îÄ‚îÄ Visualize.py             # Chart generation
‚îÇ
‚îî‚îÄ‚îÄ data/                         # Data storage
    ‚îú‚îÄ‚îÄ stopwords.txt            # Vietnamese stopwords
    ‚îú‚îÄ‚îÄ raw_comments_*.csv       # Raw scraped data
    ‚îî‚îÄ‚îÄ clean_comments_*.csv     # Processed data
```

### Pipeline Flow

```mermaid
graph LR
    A[YouTube URL] --> B[Scraper]
    B --> C{Raw CSV}
    C --> D[Cleaner]
    D --> E{Clean CSV}
    E --> F[ML Model]
    F --> G{Results CSV}
    G --> H[Visualizer]
    H --> I[Charts + WordCloud]
```

---

## ‚öôÔ∏è Configuration

### `config.py` - Centralized Settings

```python
# Scraper settings
SCRAPER = {
    "headless": True,          # Run browser in background
    "scroll_time": 30,         # Number of scroll iterations
    "window_size": "1920,1080"
}

# Model settings
MODEL = {
    "alpha": 1.0,              # Laplace smoothing
}

# Visualization settings
VISUALIZATION = {
    "max_words": 150,          # Words in word cloud
    "figure_size": (20, 8),    # Chart dimensions
}
```

### Customization

**Change scraping duration:**
```python
tool.scrape_comments(scroll_time=50)  # More comments
```

**Change visualization words:**
```python
# In config.py
VISUALIZATION["max_words"] = 200
```

---

## üìä Model Performance

| Metric | Value |
|--------|-------|
| **Algorithm** | Multinomial Naive Bayes |
| **Accuracy** | 85.31% |
| **Training Data** | 23,818 Vietnamese comments |
| **Vocabulary Size** | 10,054 unique tokens |
| **Classes** | 3 (Positive, Neutral, Negative) |

### Label Distribution (Training Data)

- **Positive (0)**: 82.6% (19,658 samples)
- **Neutral (1)**: 6.7% (1,604 samples)
- **Negative (2)**: 10.7% (2,556 samples)

---

## üîß Advanced Usage

### Train Custom Model

```python
from modules.AIModel import SentimentClassifier

model = SentimentClassifier()
model._train("path/to/your/training_data.csv")
```

**Training data format:**
```csv
text,label
"s·∫£n ph·∫©m t·ªët",0
"d·ªãch v·ª• t·ªá",2
```

### Standalone Components

```python
# Use scraper only
from modules.YoutubeCommentScraper import YoutubeCommentScraper

scraper = YoutubeCommentScraper()
scraper._get_url("https://youtube.com/watch?v=...")
scraper._scroll(30)
comments = scraper.extract_comments()
```

---

## üêõ Troubleshooting

### Common Issues

**1. ChromeDriver not found**
```bash
# Install webdriver-manager
pip install webdriver-manager
```

**2. Model not loaded**
```bash
# Train model first
python modules/AIModel.py
```

**3. Encoding errors in visualization**
- Already fixed with ASCII-safe text
- Vietnamese characters handled by ViTokenizer

---

## üìà Roadmap

- [ ] Support for multiple languages
- [ ] Real-time comment monitoring
- [ ] API endpoint deployment
- [ ] Interactive dashboard (Streamlit)
- [ ] Aspect-based sentiment analysis

---

## ü§ù Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## üìÑ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

---

## üë• Authors

- **T·ªëng Ph∆∞·ªõc Ho√†i Nam** - *Initial work* - [YourGitHub](https://github.com/tetsde)

---

## üôè Acknowledgments

- **pyvi** - Vietnamese tokenization
- **sklearn** - Machine learning framework
- **Selenium** - Web automation
- **matplotlib** - Data visualization

---

<div align="center">

**‚≠ê Star this repo if you find it helpful!**

Made with ‚ù§Ô∏è in Vietnam üáªüá≥

</div>
